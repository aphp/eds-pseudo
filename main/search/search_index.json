{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview EDS-Pseudonymisation is a spaCy-based project used at APHP to extract and replace identifying entities in medical documents. Getting started EDS-Pseudonymisation is a spaCy project . We created a single workflow that: Converts the datasets to spaCy format Trains the pipeline Evaluates the pipeline using the test set Packages the resulting model to make it pip-installable To use it, you will need to supply: A labelled dataset A HuggingFace transformers model, or use camembert-base In any case, you will need to modify the configuration to reflect these changes. Entities Label Description ADRESSE Street address, eg 33 boulevard de Picpus DATE Any absolute date other than a birthdate DATE_NAISSANCE Birthdate HOPITAL Hospital name, eg H\u00f4pital Rothschild IPP Internal AP-HP identifier for patients, displayed as a number MAIL Email address NDA Internal AP-HP identifier for visits, displayed as a number NOM Any last name (patients, doctors, third parties) PRENOM Any first name (patients, doctors, etc) SECU Social security number TEL Any phone number VILLE Any city ZIP Any zip code Commands Command Description convert Convert the data to spaCy's binary format train Train the NER model evaluate Evaluate the model and export metrics package Package the trained model as a pip package visualize-model Visualize the model's output interactively using Streamlit Run the command with spacy project run [ command ] [ options ] Take a look at the annotation guide for more detail.","title":"Overview"},{"location":"#overview","text":"EDS-Pseudonymisation is a spaCy-based project used at APHP to extract and replace identifying entities in medical documents.","title":"Overview"},{"location":"#getting-started","text":"EDS-Pseudonymisation is a spaCy project . We created a single workflow that: Converts the datasets to spaCy format Trains the pipeline Evaluates the pipeline using the test set Packages the resulting model to make it pip-installable To use it, you will need to supply: A labelled dataset A HuggingFace transformers model, or use camembert-base In any case, you will need to modify the configuration to reflect these changes.","title":"Getting started"},{"location":"#entities","text":"Label Description ADRESSE Street address, eg 33 boulevard de Picpus DATE Any absolute date other than a birthdate DATE_NAISSANCE Birthdate HOPITAL Hospital name, eg H\u00f4pital Rothschild IPP Internal AP-HP identifier for patients, displayed as a number MAIL Email address NDA Internal AP-HP identifier for visits, displayed as a number NOM Any last name (patients, doctors, third parties) PRENOM Any first name (patients, doctors, etc) SECU Social security number TEL Any phone number VILLE Any city ZIP Any zip code","title":"Entities"},{"location":"#commands","text":"Command Description convert Convert the data to spaCy's binary format train Train the NER model evaluate Evaluate the model and export metrics package Package the trained model as a pip package visualize-model Visualize the model's output interactively using Streamlit Run the command with spacy project run [ command ] [ options ] Take a look at the annotation guide for more detail.","title":"Commands"},{"location":"annotation-guide/","text":"Annotation Guide Data Selection We annotated around 4000 documents, selected according to the distribution of AP-HP's Clinical Data Warehouse (CDW), to obtain a sample that is representative of the actual documents present within the CDW. Training data are selected among notes that were edited after August 2017, in order to skew the model towards more recent clinical notes. The test set, however, is sampled without any time constraints, to make sure the model performs well overall. Annotated Entities We annotated clinical documents with the following entities : Label Description ADRESSE Street address, eg 33 boulevard de Picpus DATE Any absolute date other than a birthdate DATE_NAISSANCE Birthdate HOPITAL Hospital name, eg H\u00f4pital Rothschild IPP Internal AP-HP identifier for patients, displayed as a number MAIL Email address NDA Internal AP-HP identifier for visits, displayed as a number NOM Any last name (patients, doctors, third parties) PRENOM Any first name (patients, doctors, etc) SECU Social security number TEL Any phone number VILLE Any city ZIP Any zip code Software The software used to annotate the document with personal identification entities was LabelStudio, but any software will do. The convert step takes as input either a jsonlines file ( .jsonl ) or a folder containing Standoff files ( .ann ) from an annotation with Brat . Feel free to submit a pull request if these formats do not suit you!","title":"Annotation Guide"},{"location":"annotation-guide/#annotation-guide","text":"","title":"Annotation Guide"},{"location":"annotation-guide/#data-selection","text":"We annotated around 4000 documents, selected according to the distribution of AP-HP's Clinical Data Warehouse (CDW), to obtain a sample that is representative of the actual documents present within the CDW. Training data are selected among notes that were edited after August 2017, in order to skew the model towards more recent clinical notes. The test set, however, is sampled without any time constraints, to make sure the model performs well overall.","title":"Data Selection"},{"location":"annotation-guide/#annotated-entities","text":"We annotated clinical documents with the following entities : Label Description ADRESSE Street address, eg 33 boulevard de Picpus DATE Any absolute date other than a birthdate DATE_NAISSANCE Birthdate HOPITAL Hospital name, eg H\u00f4pital Rothschild IPP Internal AP-HP identifier for patients, displayed as a number MAIL Email address NDA Internal AP-HP identifier for visits, displayed as a number NOM Any last name (patients, doctors, third parties) PRENOM Any first name (patients, doctors, etc) SECU Social security number TEL Any phone number VILLE Any city ZIP Any zip code","title":"Annotated Entities"},{"location":"annotation-guide/#software","text":"The software used to annotate the document with personal identification entities was LabelStudio, but any software will do. The convert step takes as input either a jsonlines file ( .jsonl ) or a folder containing Standoff files ( .ann ) from an annotation with Brat . Feel free to submit a pull request if these formats do not suit you!","title":"Software"},{"location":"changelog/","text":"Changelog v0.1.0 - 2022-05-13 Inception ! Features spaCy project for pseudonymisation Pseudonymisation-specific pipelines: pseudonymisation-rules for rule-based pseudonymisation pseudonymisation-dates for date detection and normalisation structured-data-matcher for structured data detection (eg first and last name, available in the information system) Evaluation methodology","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v010-2022-05-13","text":"Inception !","title":"v0.1.0 - 2022-05-13"},{"location":"changelog/#features","text":"spaCy project for pseudonymisation Pseudonymisation-specific pipelines: pseudonymisation-rules for rule-based pseudonymisation pseudonymisation-dates for date detection and normalisation structured-data-matcher for structured data detection (eg first and last name, available in the information system) Evaluation methodology","title":"Features"},{"location":"quickstart/","text":"Quickstart Deployment This project trains our pseudonymisation pipeline, and make it pip-installable. Requirements To use this repository, you will need to supply: A labelled dataset A HuggingFace transformers model, or use a publicly available model like camembert-base In any case, you will need to modify the configuration to reflect these changes. Installation Install the requirements by running the following command at the root of the repo poetry install Training a model EDS-Pseudonymisation is a spaCy project . We created a single workflow that: Converts the datasets to spaCy format Trains the pipeline Evaluates the pipeline using the test set Packages the resulting model to make it pip-installable To add a new dataset, run dvc import-url url/or/path/to/your/dataset data/dataset To (re-)train a model and package it, just run: dvc repro You should now be able to install and publish it: pip install dist/eds_pseudonymisation-0.2.0-* Use it To use it, execute import eds_pseudonymisation nlp = eds_pseudonymisation . load () doc = nlp ( \"\"\"En 1815, M. Charles-Fran\u00e7ois-Bienvenu Myriel \u00e9tait \u00e9v\u00eaque de Digne. C\u2019\u00e9tait un vieillard d\u2019environ soixante-quinze ans ; il occupait le si\u00e8ge de Digne depuis 1806. \"\"\" ) for ent in doc . ents : print ( ent , ent . label ) # 1815 DATE # Charles-Fran\u00e7ois-Bienvenu NOM # Myriel PRENOM # Digne VILLE # 1806 DATE","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#deployment","text":"This project trains our pseudonymisation pipeline, and make it pip-installable.","title":"Deployment"},{"location":"quickstart/#requirements","text":"To use this repository, you will need to supply: A labelled dataset A HuggingFace transformers model, or use a publicly available model like camembert-base In any case, you will need to modify the configuration to reflect these changes.","title":"Requirements"},{"location":"quickstart/#installation","text":"Install the requirements by running the following command at the root of the repo poetry install","title":"Installation"},{"location":"quickstart/#training-a-model","text":"EDS-Pseudonymisation is a spaCy project . We created a single workflow that: Converts the datasets to spaCy format Trains the pipeline Evaluates the pipeline using the test set Packages the resulting model to make it pip-installable To add a new dataset, run dvc import-url url/or/path/to/your/dataset data/dataset To (re-)train a model and package it, just run: dvc repro You should now be able to install and publish it: pip install dist/eds_pseudonymisation-0.2.0-*","title":"Training a model"},{"location":"quickstart/#use-it","text":"To use it, execute import eds_pseudonymisation nlp = eds_pseudonymisation . load () doc = nlp ( \"\"\"En 1815, M. Charles-Fran\u00e7ois-Bienvenu Myriel \u00e9tait \u00e9v\u00eaque de Digne. C\u2019\u00e9tait un vieillard d\u2019environ soixante-quinze ans ; il occupait le si\u00e8ge de Digne depuis 1806. \"\"\" ) for ent in doc . ents : print ( ent , ent . label ) # 1815 DATE # Charles-Fran\u00e7ois-Bienvenu NOM # Myriel PRENOM # Digne VILLE # 1806 DATE","title":"Use it"},{"location":"reproducibility/","text":"Reproducibility To guarantee the reproducibility of our models, we rely on virtual environments and VCS tools. Environments We use Poetry to validate the constraints generated by the dependencies of our model, and lock the versions that were used to generate a model, in a poetry.lock file. This file can be reused to reinstall a previous environment by running poetry install Versioning We use DVC to version the experiences, models and datasets used. To add and version a new dataset, run dvc import-url url/or/path/to/your/dataset data/dataset To (re-)train a model and package it, just run: dvc repro For more information about DVC, make sure to visit their documentation .","title":"Reproducibility"},{"location":"reproducibility/#reproducibility","text":"To guarantee the reproducibility of our models, we rely on virtual environments and VCS tools.","title":"Reproducibility"},{"location":"reproducibility/#environments","text":"We use Poetry to validate the constraints generated by the dependencies of our model, and lock the versions that were used to generate a model, in a poetry.lock file. This file can be reused to reinstall a previous environment by running poetry install","title":"Environments"},{"location":"reproducibility/#versioning","text":"We use DVC to version the experiences, models and datasets used. To add and version a new dataset, run dvc import-url url/or/path/to/your/dataset data/dataset To (re-)train a model and package it, just run: dvc repro For more information about DVC, make sure to visit their documentation .","title":"Versioning"},{"location":"results/","text":"Results Stay tuned for the publication of our article. We will update this page as well with the conclusion of our experiments.","title":"Results"},{"location":"results/#results","text":"Stay tuned for the publication of our article. We will update this page as well with the conclusion of our experiments.","title":"Results"}]}