{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview EDS-Pseudonymisation is a spaCy-based project used at APHP to extract and replace identifying entities in medical documents. Getting started EDS-Pseudonymisation is a spaCy project . We created a single workflow that: Converts the datasets to spaCy format Trains the pipeline Evaluates the pipeline using the test set Packages the resulting model to make it pip-installable To use it, you will need to supply: A labelled dataset A HuggingFace transformers model, or use camembert-base In any case, you will need to modify the configuration to reflect these changes. Entities Label Description ADRESSE Street address, eg 33 boulevard de Picpus DATE Any absolute date other than a birthdate DATE_NAISSANCE Birthdate HOPITAL Hospital name, eg H\u00f4pital Rothschild IPP Internal AP-HP identifier for patients, displayed as a number MAIL Email address NDA Internal AP-HP identifier for visits, displayed as a number NOM Any last name (patients, doctors, third parties) PRENOM Any first name (patients, doctors, etc) SECU Social security number TEL Any phone number VILLE Any city ZIP Any zip code Commands Command Description convert Convert the data to spaCy's binary format train Train the NER model evaluate Evaluate the model and export metrics package Package the trained model as a pip package visualize-model Visualize the model's output interactively using Streamlit Run the command with spacy project run [ command ] [ options ]","title":"Overview"},{"location":"#overview","text":"EDS-Pseudonymisation is a spaCy-based project used at APHP to extract and replace identifying entities in medical documents.","title":"Overview"},{"location":"#getting-started","text":"EDS-Pseudonymisation is a spaCy project . We created a single workflow that: Converts the datasets to spaCy format Trains the pipeline Evaluates the pipeline using the test set Packages the resulting model to make it pip-installable To use it, you will need to supply: A labelled dataset A HuggingFace transformers model, or use camembert-base In any case, you will need to modify the configuration to reflect these changes.","title":"Getting started"},{"location":"#entities","text":"Label Description ADRESSE Street address, eg 33 boulevard de Picpus DATE Any absolute date other than a birthdate DATE_NAISSANCE Birthdate HOPITAL Hospital name, eg H\u00f4pital Rothschild IPP Internal AP-HP identifier for patients, displayed as a number MAIL Email address NDA Internal AP-HP identifier for visits, displayed as a number NOM Any last name (patients, doctors, third parties) PRENOM Any first name (patients, doctors, etc) SECU Social security number TEL Any phone number VILLE Any city ZIP Any zip code","title":"Entities"},{"location":"#commands","text":"Command Description convert Convert the data to spaCy's binary format train Train the NER model evaluate Evaluate the model and export metrics package Package the trained model as a pip package visualize-model Visualize the model's output interactively using Streamlit Run the command with spacy project run [ command ] [ options ]","title":"Commands"},{"location":"changelog/","text":"Changelog v0.2.0 - 2023-05-04 Many fixes along the publication of our article : Tests for the rule-based components Code documentation and cleaning Experiment and analysis scripts Charts and tables in the Results page of our documentation v0.1.0 - 2022-05-13 Inception ! Features spaCy project for pseudonymisation Pseudonymisation-specific pipelines: pseudonymisation-rules for rule-based pseudonymisation pseudonymisation-dates for date detection and normalisation structured-data-matcher for structured data detection (eg first and last name, available in the information system) Evaluation methodology","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v020-2023-05-04","text":"Many fixes along the publication of our article : Tests for the rule-based components Code documentation and cleaning Experiment and analysis scripts Charts and tables in the Results page of our documentation","title":"v0.2.0 - 2023-05-04"},{"location":"changelog/#v010-2022-05-13","text":"Inception !","title":"v0.1.0 - 2022-05-13"},{"location":"changelog/#features","text":"spaCy project for pseudonymisation Pseudonymisation-specific pipelines: pseudonymisation-rules for rule-based pseudonymisation pseudonymisation-dates for date detection and normalisation structured-data-matcher for structured data detection (eg first and last name, available in the information system) Evaluation methodology","title":"Features"},{"location":"dataset/","text":"Dataset Disclaimer We do not provide the dataset due to privacy and regulatory constraints. You will however find the description of the dataset below. We also release the code for the rule-based annotation system. Data Selection We annotated around 4000 documents, selected according to the distribution of AP-HP's Clinical Data Warehouse (CDW), to obtain a sample that is representative of the actual documents present within the CDW. Training data are selected among notes that were edited after August 2017, in order to skew the model towards more recent clinical notes. The test set, however, is sampled without any time constraints, to make sure the model performs well overall. To ensure the robustness of the model, training and test sets documents were generated from two different PDF extraction methods: the legacy method, based on PDFBox with a fixed mask our new method EDS-PDF with an adaptative (machine-learned) mask Annotated Entities We annotated clinical documents with the following entities : Label Description ADRESSE Street address, eg 33 boulevard de Picpus DATE Any absolute date other than a birthdate DATE_NAISSANCE Birthdate HOPITAL Hospital name, eg H\u00f4pital Rothschild IPP Internal AP-HP identifier for patients, displayed as a number MAIL Email address NDA Internal AP-HP identifier for visits, displayed as a number NOM Any last name (patients, doctors, third parties) PRENOM Any first name (patients, doctors, etc) SECU Social security number TEL Any phone number VILLE Any city ZIP Any zip code Statistics To inspect the statistics for the latest version of our dataset, please refer to the latest release . Software The software tools used to annotate the documents with personal identification entities were: LabelStudio for the first annotation campaign Metanno for the second annotation campaign but any annotation software will do. The convert step takes as input either a jsonlines file ( .jsonl ) or a folder containing Standoff files ( .ann ) from an annotation with Brat . Feel free to submit a pull request if these formats do not suit you!","title":"Dataset"},{"location":"dataset/#dataset","text":"Disclaimer We do not provide the dataset due to privacy and regulatory constraints. You will however find the description of the dataset below. We also release the code for the rule-based annotation system.","title":"Dataset"},{"location":"dataset/#data-selection","text":"We annotated around 4000 documents, selected according to the distribution of AP-HP's Clinical Data Warehouse (CDW), to obtain a sample that is representative of the actual documents present within the CDW. Training data are selected among notes that were edited after August 2017, in order to skew the model towards more recent clinical notes. The test set, however, is sampled without any time constraints, to make sure the model performs well overall. To ensure the robustness of the model, training and test sets documents were generated from two different PDF extraction methods: the legacy method, based on PDFBox with a fixed mask our new method EDS-PDF with an adaptative (machine-learned) mask","title":"Data Selection"},{"location":"dataset/#annotated-entities","text":"We annotated clinical documents with the following entities : Label Description ADRESSE Street address, eg 33 boulevard de Picpus DATE Any absolute date other than a birthdate DATE_NAISSANCE Birthdate HOPITAL Hospital name, eg H\u00f4pital Rothschild IPP Internal AP-HP identifier for patients, displayed as a number MAIL Email address NDA Internal AP-HP identifier for visits, displayed as a number NOM Any last name (patients, doctors, third parties) PRENOM Any first name (patients, doctors, etc) SECU Social security number TEL Any phone number VILLE Any city ZIP Any zip code","title":"Annotated Entities"},{"location":"dataset/#statistics","text":"To inspect the statistics for the latest version of our dataset, please refer to the latest release .","title":"Statistics"},{"location":"dataset/#software","text":"The software tools used to annotate the documents with personal identification entities were: LabelStudio for the first annotation campaign Metanno for the second annotation campaign but any annotation software will do. The convert step takes as input either a jsonlines file ( .jsonl ) or a folder containing Standoff files ( .ann ) from an annotation with Brat . Feel free to submit a pull request if these formats do not suit you!","title":"Software"},{"location":"quickstart/","text":"Quickstart Deployment This project trains our pseudonymisation pipeline, and make it pip-installable. Requirements To use this repository, you will need to supply: A labelled dataset A HuggingFace transformers model, or use a publicly available model like camembert-base In any case, you will need to modify the configuration to reflect these changes. Installation Install the requirements by running the following command at the root of the repo poetry install Training a model EDS-Pseudonymisation is a spaCy project . We created a single workflow that: Converts the datasets to spaCy format Trains the pipeline Evaluates the pipeline using the test set Packages the resulting model to make it pip-installable To add a new dataset, run dvc import-url url/or/path/to/your/dataset data/dataset To (re-)train a model and package it, just run: dvc repro You should now be able to install and publish it: pip install dist/eds_pseudonymisation-0.2.0-* Use it To use it, execute import eds_pseudonymisation nlp = eds_pseudonymisation . load () doc = nlp ( \"\"\"En 1815, M. Charles-Fran\u00e7ois-Bienvenu Myriel \u00e9tait \u00e9v\u00eaque de Digne. C\u2019\u00e9tait un vieillard d\u2019environ soixante-quinze ans ; il occupait le si\u00e8ge de Digne depuis 1806. \"\"\" ) for ent in doc . ents : print ( ent , ent . label ) # 1815 DATE # Charles-Fran\u00e7ois-Bienvenu NOM # Myriel PRENOM # Digne VILLE # 1806 DATE","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#deployment","text":"This project trains our pseudonymisation pipeline, and make it pip-installable.","title":"Deployment"},{"location":"quickstart/#requirements","text":"To use this repository, you will need to supply: A labelled dataset A HuggingFace transformers model, or use a publicly available model like camembert-base In any case, you will need to modify the configuration to reflect these changes.","title":"Requirements"},{"location":"quickstart/#installation","text":"Install the requirements by running the following command at the root of the repo poetry install","title":"Installation"},{"location":"quickstart/#training-a-model","text":"EDS-Pseudonymisation is a spaCy project . We created a single workflow that: Converts the datasets to spaCy format Trains the pipeline Evaluates the pipeline using the test set Packages the resulting model to make it pip-installable To add a new dataset, run dvc import-url url/or/path/to/your/dataset data/dataset To (re-)train a model and package it, just run: dvc repro You should now be able to install and publish it: pip install dist/eds_pseudonymisation-0.2.0-*","title":"Training a model"},{"location":"quickstart/#use-it","text":"To use it, execute import eds_pseudonymisation nlp = eds_pseudonymisation . load () doc = nlp ( \"\"\"En 1815, M. Charles-Fran\u00e7ois-Bienvenu Myriel \u00e9tait \u00e9v\u00eaque de Digne. C\u2019\u00e9tait un vieillard d\u2019environ soixante-quinze ans ; il occupait le si\u00e8ge de Digne depuis 1806. \"\"\" ) for ent in doc . ents : print ( ent , ent . label ) # 1815 DATE # Charles-Fran\u00e7ois-Bienvenu NOM # Myriel PRENOM # Digne VILLE # 1806 DATE","title":"Use it"},{"location":"reproducibility/","text":"Reproducibility To guarantee the reproducibility of our models, we rely on virtual environments and VCS tools. Environments We use Poetry to validate the constraints generated by the dependencies of our model, and lock the versions that were used to generate a model, in a poetry.lock file. This file can be reused to reinstall a previous environment by running poetry install --with docs Versioning We use DVC to version the experiences, models and datasets used. To add and version a new dataset, run dvc import-url url/or/path/to/your/dataset data/dataset To (re-)train a model and package it, just run: dvc repro For more information about DVC, make sure to visit their documentation . Article experiments To reproduce the results of our article, run the experiments.py script to queue and run all the experiments with DVC: $ python scripts/experiments.py $ dvc exp run --queue --run-all Tip for Slurm environments If your computing resources are managed with Slurm, you can run dvc exp queue-worker from Slurm jobs instead of the last command to parallelize the experiments across multiple nodes. my_slurm_job.sh # SBATCH ... dvc exp queue-worker dvc-worker- $SLURM_JOB_ID -v $ sbatch my_slurm_job.sh # first job $ sbatch my_slurm_job.sh # launch as many jobs at once as needed To reproduce (some) of the figures of our article, run the analysis.py script to generate the charts and tables in the docs/assets/figures folder. $ python scripts/analysis.py INFO:root:Loading experiments INFO:root:Found 110 experiments INFO:root:Building corpus statistics table INFO:root:Computing results table, this can take a while ... INFO:root:Plotting BERT ablation experiments INFO:root:Plotting results by labels INFO:root:Plotting document type ablation experiments INFO:root:Building comparison table of PDF extraction methods INFO:root:Building comparison table of ML vs rule-based and visualize them by serving the documentation $ mkdocs serve","title":"Reproducibility"},{"location":"reproducibility/#reproducibility","text":"To guarantee the reproducibility of our models, we rely on virtual environments and VCS tools.","title":"Reproducibility"},{"location":"reproducibility/#environments","text":"We use Poetry to validate the constraints generated by the dependencies of our model, and lock the versions that were used to generate a model, in a poetry.lock file. This file can be reused to reinstall a previous environment by running poetry install --with docs","title":"Environments"},{"location":"reproducibility/#versioning","text":"We use DVC to version the experiences, models and datasets used. To add and version a new dataset, run dvc import-url url/or/path/to/your/dataset data/dataset To (re-)train a model and package it, just run: dvc repro For more information about DVC, make sure to visit their documentation .","title":"Versioning"},{"location":"reproducibility/#article-experiments","text":"To reproduce the results of our article, run the experiments.py script to queue and run all the experiments with DVC: $ python scripts/experiments.py $ dvc exp run --queue --run-all Tip for Slurm environments If your computing resources are managed with Slurm, you can run dvc exp queue-worker from Slurm jobs instead of the last command to parallelize the experiments across multiple nodes. my_slurm_job.sh # SBATCH ... dvc exp queue-worker dvc-worker- $SLURM_JOB_ID -v $ sbatch my_slurm_job.sh # first job $ sbatch my_slurm_job.sh # launch as many jobs at once as needed To reproduce (some) of the figures of our article, run the analysis.py script to generate the charts and tables in the docs/assets/figures folder. $ python scripts/analysis.py INFO:root:Loading experiments INFO:root:Found 110 experiments INFO:root:Building corpus statistics table INFO:root:Computing results table, this can take a while ... INFO:root:Plotting BERT ablation experiments INFO:root:Plotting results by labels INFO:root:Plotting document type ablation experiments INFO:root:Building comparison table of PDF extraction methods INFO:root:Building comparison table of ML vs rule-based and visualize them by serving the documentation $ mkdocs serve","title":"Article experiments"},{"location":"results/","text":"Results Our article is available on arXiv . To inspect the results for the latest version of our system, please refer to the latest release page.","title":"Results"},{"location":"results/#results","text":"Our article is available on arXiv . To inspect the results for the latest version of our system, please refer to the latest release page.","title":"Results"}]}