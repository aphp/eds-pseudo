# ---- General ----
[vars]
ml_spans = "pseudo-ml"
rb_spans = "pseudo-rb"
hybrid_spans = "ents"
limit = -1

# ---- Pipeline ----
[nlp]
lang = "eds"
pipeline = [
    "normalizer",
    # Not enough specificity compared to ml alone, you may want to comment it :
    #"dates",
    "simple-rules",
    "addresses",
    "context",
    # Trainable NER component :
    "ner",
    "clean",
    "merge",
    "dates-normalizer"
    ]
batch_size = 32
components = ${components}

[components.normalizer]
@factory = "eds.normalizer"

[components.sentencizer]
@factory = "eds.sentences"

[components.remove-lowercase]
@factory = "eds.remove_lowercase"

[components.dates]
@factory = "eds_pseudo.dates"
span_setter = ${vars.rb_spans}

[components.simple-rules]
@factory = "eds_pseudo.simple_rules"
pattern_keys = [
    "TEL",
    "MAIL",
    "SECU",
    # Not enough specificity compared to ml alone, you may want to comment it :
    #"PERSON",
    ]
span_setter = ${vars.rb_spans}

[components.addresses]
@factory = "eds_pseudo.addresses"
span_setter = ${vars.rb_spans}

[components.context]
@factory = "eds_pseudo.context"
span_setter = ${vars.rb_spans}

[components.embedding]
@factory = "eds.text_cnn"
kernel_sizes = [3]

[components.embedding.embedding]
@factory = "eds.transformer"
# You should change this for another base model (accepts a huggingface model name or a path)
model = "camembert-base"
window = 128
stride = 96
# Represent newlines as a new learnable token (removed by *bert tokenizers by default) :
new_tokens = [ [ "(?:\n\s*)*\n", "‚èé" ] ]

[components.ner]
@factory = "eds.ner_crf"
# window = 1 means no CRF during inference, equivalent to simple softmax :
# window = 1
# therefore, we train with "independent" mode :
mode = "joint"
target_span_getter = ${vars.ml_spans}
span_setter = ${vars.ml_spans}
embedding = ${components.embedding}

[components.clean]
@factory = "eds_pseudo.clean"
span_getter = [ ${vars.rb_spans}, ${vars.ml_spans}, ${vars.hybrid_spans} ]

[components.merge]
@factory = "eds_pseudo.merge"
span_getter = [ ${vars.rb_spans}, ${vars.ml_spans} ]
# This will output entities in doc.ents, doc.spans[ml_spans] and
# "*" means it will create a new span group for each type of span :
span_setter = [ "ents", ${vars.hybrid_spans}, "*" ]

[components.dates-normalizer]
@factory = "eds_pseudo.dates_normalizer"
span_getter = { "ents" : ["DATE", "DATE_NAISSANCE"] }
format = "strftime"

[scorers]
rb_spans = ${vars.rb_spans}
ml_spans = ${vars.ml_spans}
hybrid_spans = ${vars.hybrid_spans}
labels = ["ADRESSE", "DATE", "DATE_NAISSANCE", "IPP", "MAIL", "NDA", "NOM", "PRENOM", "SECU", "TEL", "VILLE", "ZIP"]

# ---- Datasets ----
[training_docs]
randomize = true
# Each training sample will be 256 words or less (regardless of the window size
# used by the transformer)
max_length = 256
multi_sentence = true
limit = ${vars.limit}
[training_docs.source]
@readers = "json"  # or parquet or standoff
converter = "pseudo"  # defined in eds_pseudo/adapter.py
path = "data/gen_dataset/train.jsonl"
doc_attributes = [ "context", "note_datetime", "note_class_source_value" ]
span_setter = [ ${vars.ml_spans}, ${vars.rb_spans}, ${vars.hybrid_spans} ]

[val_docs]
[val_docs.source]
@readers = "json"  # or parquet or standoff
converter = "pseudo"  # defined in eds_pseudo/adapter.py
path = "data/dataset/dev.jsonl"
# Use a limit if your validation dataset is too big (e.g., gen_dataset/train.jsonl)
# limit = 10
doc_attributes = [ "context", "note_datetime", "note_class_source_value" ]
span_setter = [ ${vars.ml_spans}, ${vars.rb_spans}, ${vars.hybrid_spans} ]

[test_docs]
[test_docs.source]
@readers = "json"  # or parquet or standoff
converter = "pseudo"  # defined in eds_pseudo/adapter.py
path = "data/dataset/test.jsonl"
doc_attributes = [ "context", "note_datetime", "note_class_source_value" ]
span_setter = [ ${vars.ml_spans}, ${vars.rb_spans}, ${vars.hybrid_spans} ]

# ---- Scripts ----
[train]
nlp = ${nlp}
max_steps = 2000
validation_interval = ${train.max_steps//10}
batch_size = 2000 words
embedding_lr = 5e-5
task_lr = 5e-5
seed = 43
scorer = ${scorers}
# You can put more than one dataset in the list below
train_data = [ ${training_docs} ]
val_data = ${val_docs}
# Adjust this to the VRAM of your GPU
grad_accumulation_max_tokens = 32000
# Use this if you're on a M1 Mac, or if you don't want to use CUDA
# cpu = true

[evaluate]
scorer = ${scorers}
dataset_name = "AP-HP Pseudo Test"
data = ${test_docs}

[package]
# Suggestion: choose a name that mixes both the architecture (eds-pseudo) and the
# dataset on which the model was trained (aphp)
# This field will be read by script/package.py
name = "eds-pseudo-public"
hf_name = "AP-HP/eds-pseudo-public"  # this is only used to update the packaged README
