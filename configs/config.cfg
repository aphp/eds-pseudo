[nlp]
lang = "eds"
pipeline = [
    "normalizer",
    "sentencizer",
    "embedding",
    "ner",
    "dates",
    "simple-rules",
    "addresses",
    "context",
    "merge",
    "clean"
    ]
batch_size = 32
components = ${components}

[components.normalizer]
@factory = "eds.normalizer"

[components.sentencizer]
@factory = "eds.sentences"

[components.remove-lowercase]
@factory = "eds.remove_lowercase"

[components.dates]
@factory = "eds_pseudo.dates"
span_setter = ${vars.rb_spans}

[components.simple-rules]
@factory = "eds_pseudo.simple_rules"
pattern_keys = ["TEL", "MAIL", "SECU", "PERSON"]
span_setter = ${vars.rb_spans}

[components.addresses]
@factory = "eds_pseudo.addresses"
span_setter = ${vars.rb_spans}

[components.context]
@factory = "eds_pseudo.context"
span_setter = ${vars.rb_spans}

[components.clean]
@factory = "eds_pseudo.clean"
span_getter = [ ${vars.rb_spans}, ${vars.ml_spans} ]

[components.embedding]
@factory = "eds.text_cnn"
kernel_sizes = [3]

[components.embedding.embedding]
@factory = "eds.transformer"
model = "hf-internal-testing/tiny-bert"
window = 128
stride = 96
new_tokens = [ [ "(?:\n\s*)*\n", "‚èé" ] ]

[components.ner]
@factory = "eds.ner_crf"
mode = "joint"
target_span_getter = ${vars.ml_spans}
span_setter = ${vars.ml_spans}
window = 0
embedding = ${components.embedding}

[components.merge]
@factory = "eds_pseudo.merge"
span_getter = [ ${vars.rb_spans}, ${vars.ml_spans} ]
span_setter = [ "ents", ${vars.hybrid_spans} ]

[scorers]
exact_ner_ml = {
    "@scorers": "eds.ner_exact_scorer",
    "span_getter": ${vars.ml_spans} }
exact_ner_rb = {
    "@scorers": "eds.ner_exact_scorer",
    "span_getter": ${vars.rb_spans} }
exact_ner_hybrid = {
    "@scorers": "eds.ner_exact_scorer",
    "span_getter": ${vars.hybrid_spans} }
token_ner_hybrid = {
    "@scorers": "eds.ner_token_scorer",
    "span_getter": ${vars.hybrid_spans} }
token_ner_ml = {
    "@scorers": "eds.ner_token_scorer",
    "span_getter": ${vars.ml_spans} }

[vars]
train = "data/dataset/train.jsonl"
dev = "data/dataset/dev.jsonl"
test = "data/dataset/test.jsonl"
ml_spans = "pseudo-ml"
rb_spans = "pseudo-rb"
hybrid_spans = "pseudo-hybrid"

[train]
nlp = ${nlp}
max_steps = 4000
validation_interval = ${train.max_steps//10}
batch_size = 1000 words
embedding_lr = 5e-5
task_lr = 3e-4
seed = 42
scorer = ${scorers}

[train.train_data]
@misc = "pseudo-dataset"
path = ${vars.train}
multi_sentence = true
max_length = 50
randomize = true

[train.val_data]
@misc = "pseudo-dataset"
path = ${vars.dev}
