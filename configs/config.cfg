[nlp]
lang = "eds"
pipeline = [
           "normalizer",
           "sentencizer",
           "embedding",
           "ner",
           "dates",
           "simple-rules",
           "addresses",
           "context",
           "merge",
           "clean"
           ]
batch_size = 32
components = ${components}

[components.normalizer]
@factory = "eds.normalizer"

[components.sentencizer]
@factory = "eds.sentences"

[components.remove-lowercase]
@factory = "eds.remove_lowercase"

[components.dates]
@factory = "eds_pseudo.dates"
span_setter = ${vars.rb_spans}

[components.simple-rules]
@factory = "eds_pseudo.simple_rules"
pattern_keys = ["TEL", "MAIL", "SECU", "PERSON"]
span_setter = ${vars.rb_spans}

[components.addresses]
@factory = "eds_pseudo.addresses"
span_setter = ${vars.rb_spans}

[components.context]
@factory = "eds_pseudo.context"
span_setter = ${vars.rb_spans}

[components.clean]
@factory = "eds_pseudo.clean"
span_getter = [ ${vars.rb_spans}, ${vars.ml_spans} ]

[components.embedding]
@factory = "eds.text_cnn"
kernel_sizes = [3]

[components.embedding.embedding]
@factory = "eds.transformer"
model = "hf-internal-testing/tiny-bert"
window = 128
stride = 96
new_tokens = [ [ "(?:\n\s*)*\n", "‚èé" ] ]

[components.ner]
@factory = "eds.ner_crf"
mode = "joint"
target_span_getter = ${vars.ml_spans}
span_setter = ${vars.ml_spans}
window = 0
embedding = ${components.embedding}

[components.merge]
@factory = "eds_pseudo.merge"
span_getter = [ ${vars.rb_spans}, ${vars.ml_spans} ]
span_setter = [ "ents", ${vars.hybrid_spans} ]

[scorers]
rb_spans = ${vars.rb_spans}
ml_spans = ${vars.ml_spans}
hybrid_spans = ${vars.hybrid_spans}

[vars]
ml_spans = "pseudo-ml"
rb_spans = "pseudo-rb"
hybrid_spans = "pseudo-hybrid"
real_data_limit = -1
gen_data_limit = 0

# Datasets
[training_docs_real]
randomize = true
max_length = 50
multi_sentence = true
limit = ${vars.real_data_limit}
[training_docs_real.source]
@readers = "json"
converter = "pseudo"
path = "data/dataset/train.jsonl"
doc_attributes = [ "context", "note_datetime", "note_class_source_value" ]
span_setter = [ ${vars.ml_spans}, ${vars.rb_spans}, ${vars.hybrid_spans} ]

[training_docs_gen]
randomize = true
max_length = 50
multi_sentence = true
limit = ${vars.gen_data_limit}
[training_docs_gen.source]
@readers = "json"
converter = "pseudo"
path = "data/gen_dataset/train.jsonl"
span_setter = [ ${vars.ml_spans}, ${vars.rb_spans}, ${vars.hybrid_spans} ]

[val_docs]
[val_docs.source]
@readers = "json"
converter = "pseudo"
path = "data/dataset/dev.jsonl"
span_setter = [ ${vars.ml_spans}, ${vars.rb_spans}, ${vars.hybrid_spans} ]

[test_docs]
[test_docs.source]
@readers = "json"
converter = "pseudo"
path = "data/dataset/test.jsonl"
span_setter = [ ${vars.ml_spans}, ${vars.rb_spans}, ${vars.hybrid_spans} ]

# ---- Scripts ----

[train]
nlp = ${nlp}
max_steps = 1000
validation_interval = ${train.max_steps//10}
batch_size = 1000 words
embedding_lr = 5e-5
task_lr = 3e-4
seed = 42
scorer = ${scorers}
train_data = [ ${training_docs_real}, ${training_docs_gen} ]
val_data = ${val_docs}

[evaluate]
scorer = ${scorers}
model_path = "artifacts/model-last"
data = ${test_docs}
